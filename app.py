"""
Chatbot Interno USITTEL - RAG con Google Sheets y Gemini
Desarrollado para consultas deterministas sobre clientes, NAPs, tickets, etc.
"""

import streamlit as st
import pandas as pd
import google.generativeai as genai
import json
import os
from datetime import datetime
from typing import Dict, Optional, List

# ==================== CONFIGURACIÃ“N ====================

# Configurar la API key de Gemini
# Intenta primero desde variables de entorno (.env), luego desde secrets.toml
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    try:
        GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    except:
        GEMINI_API_KEY = ""

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# URLs de Google Sheets (convertidas a formato CSV exportable)
SHEETS_URLS = {
    "naps": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=443573341",
    "clientes_naps": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=443573341",
    "clientes_cuentas": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=101720087",
    "clientes_datos": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=1694258191",
    "tickets": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=0",
    "clientes_olts": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=819538991",
    "dashboards": "https://docs.google.com/spreadsheets/d/1OjVaDvgzWyxDEY4u-3OJrQ8KIFUSpvMOvNT73VZb-FE/export?format=csv&gid=44575307"
}

# ==================== FUNCIONES DE CARGA DE DATOS ====================

@st.cache_data(ttl=60)  # Cache de 60 segundos para datos frescos
def cargar_google_sheet(url: str, nombre: str) -> Optional[pd.DataFrame]:
    """
    Carga una Google Sheet como DataFrame de Pandas.
    
    Args:
        url: URL de exportaciÃ³n CSV de Google Sheets
        nombre: Nombre descriptivo de la hoja (para logs)
    
    Returns:
        DataFrame con los datos o None si falla
    """
    try:
        df = pd.read_csv(url)
        st.sidebar.success(f"âœ… {nombre}: {len(df)} filas cargadas")
        return df
    except Exception as e:
        st.sidebar.error(f"âŒ Error en {nombre}: {str(e)}")
        return None

@st.cache_data(ttl=60)
def cargar_todos_los_datos() -> Dict[str, pd.DataFrame]:
    """
    Carga todas las hojas de Google Sheets.
    
    Returns:
        Diccionario con nombre_hoja: DataFrame
    """
    dataframes = {}
    
    with st.spinner("ğŸ”„ Cargando datos de Google Sheets..."):
        for nombre, url in SHEETS_URLS.items():
            df = cargar_google_sheet(url, nombre)
            if df is not None:
                dataframes[nombre] = df
    
    return dataframes

# ==================== FUNCIONES DE IA ====================

def crear_prompt_router(pregunta: str, dataframes: Dict[str, pd.DataFrame]) -> str:
    """
    Crea el prompt para que la IA decida dÃ³nde buscar.
    
    Args:
        pregunta: Pregunta del usuario
        dataframes: Diccionario de DataFrames disponibles
    
    Returns:
        Prompt formateado para el modelo
    """
    # Crear descripciÃ³n de las fuentes de datos disponibles
    descripcion_fuentes = ""
    for nombre, df in dataframes.items():
        columnas = ", ".join(df.columns.tolist()[:10])  # Primeras 10 columnas
        total_filas = len(df)
        descripcion_fuentes += f"\n- **{nombre}** ({total_filas} registros): {columnas}"
    
    prompt = f"""Eres un experto en anÃ¡lisis de datos para un ISP llamado USITTEL.

PREGUNTA DEL USUARIO:
{pregunta}

FUENTES DE DATOS DISPONIBLES:
{descripcion_fuentes}

TAREA:
Analiza la pregunta y determina:
1. En quÃ© fuente de datos (DataFrame) buscar
2. QuÃ© columna filtrar (puede ser vacÃ­o si es una pregunta general)
3. QuÃ© valor buscar (puede ser vacÃ­o si es un conteo o pregunta general)

EJEMPLOS:
- "Â¿CuÃ¡ntos clientes hay?" â†’ {{"dataframe": "clientes_datos", "columna": "", "valor": ""}}
- "Â¿CuÃ¡ntas NAPs hay?" â†’ {{"dataframe": "naps", "columna": "", "valor": ""}}
- "Â¿CuÃ¡l es el estado de Juan Perez?" â†’ {{"dataframe": "clientes_datos", "columna": "Nombre", "valor": "Juan Perez"}}

RESPONDE ÃšNICAMENTE con un JSON vÃ¡lido en este formato:
{{
    "dataframe": "nombre_del_dataframe",
    "columna": "nombre_de_columna_o_vacio",
    "valor": "valor_a_buscar_o_vacio",
    "explicacion": "breve explicaciÃ³n"
}}

Si no puedes determinar dÃ³nde buscar, responde:
{{
    "error": "No puedo determinar dÃ³nde buscar esta informaciÃ³n"
}}
"""
    return prompt

def llamar_gemini(prompt: str, temperatura: float = 0.1) -> str:
    """
    Llama a la API de Gemini y retorna la respuesta.
    
    Args:
        prompt: Texto del prompt
        temperatura: Nivel de creatividad (0 = determinista, 1 = creativo)
    
    Returns:
        Respuesta del modelo
    """
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=temperatura,
            )
        )
        return response.text
    except Exception as e:
        return f"Error al llamar a Gemini: {str(e)}"

def extraer_json_de_respuesta(texto: str) -> Optional[dict]:
    """
    Extrae un JSON de la respuesta del modelo.
    
    Args:
        texto: Texto que puede contener JSON
    
    Returns:
        Diccionario con el JSON parseado o None
    """
    try:
        # Intentar parsear directamente
        return json.loads(texto)
    except:
        # Buscar JSON entre marcadores de cÃ³digo
        import re
        json_match = re.search(r'```json\s*(.*?)\s*```', texto, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except:
                pass
        
        # Buscar cualquier objeto JSON en el texto
        json_match = re.search(r'\{.*\}', texto, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except:
                pass
    
    return None

# ==================== MOTOR DE BÃšSQUEDA ====================

def buscar_en_dataframe(df: pd.DataFrame, columna: str, valor: str) -> pd.DataFrame:
    """
    Realiza una bÃºsqueda exacta en un DataFrame.
    
    Args:
        df: DataFrame donde buscar
        columna: Nombre de la columna (puede estar vacÃ­o para bÃºsquedas generales)
        valor: Valor a buscar (puede estar vacÃ­o para retornar todo)
    
    Returns:
        DataFrame filtrado con los resultados
    """
    try:
        # Si no hay columna ni valor, retornar todo el DataFrame
        if not columna and not valor:
            return df
        
        # Si no hay columna pero hay valor, buscar en todas las columnas de texto
        if not columna and valor:
            mascara_global = pd.Series([False] * len(df))
            for col in df.columns:
                if df[col].dtype == 'object':
                    mascara_global |= df[col].astype(str).str.contains(str(valor), case=False, na=False)
            return df[mascara_global]
        
        # Verificar que la columna existe
        if columna not in df.columns:
            # Intentar bÃºsqueda case-insensitive en nombres de columnas
            columnas_lower = {col.lower(): col for col in df.columns}
            if columna.lower() in columnas_lower:
                columna = columnas_lower[columna.lower()]
            else:
                st.warning(f"âš ï¸ Columna '{columna}' no encontrada. Columnas disponibles: {', '.join(df.columns.tolist()[:5])}")
                return pd.DataFrame()
        
        # Si hay columna pero no valor, retornar todo
        if columna and not valor:
            return df
        
        # Realizar bÃºsqueda (case-insensitive si es texto)
        if df[columna].dtype == 'object':
            mascara = df[columna].astype(str).str.contains(str(valor), case=False, na=False)
        else:
            mascara = df[columna] == valor
        
        return df[mascara]
    
    except Exception as e:
        st.error(f"âŒ Error en bÃºsqueda: {str(e)}")
        return pd.DataFrame()

# ==================== SINTETIZADOR ====================

def crear_prompt_sintetizador(pregunta: str, resultados: pd.DataFrame, dataframe_nombre: str) -> str:
    """
    Crea el prompt para que la IA sintetice la respuesta final.
    
    Args:
        pregunta: Pregunta original del usuario
        resultados: DataFrame con los resultados encontrados
        dataframe_nombre: Nombre de la fuente de datos
    
    Returns:
        Prompt formateado
    """
    if resultados.empty:
        prompt = f"""La bÃºsqueda en '{dataframe_nombre}' no arrojÃ³ resultados para: "{pregunta}"

Responde de forma amable indicando que no se encontrÃ³ informaciÃ³n y sugiere reformular la pregunta."""
    else:
        # Para conteos o preguntas generales, mostrar estadÃ­sticas
        total_registros = len(resultados)
        
        # Si hay muchos registros, mostrar solo los primeros
        if total_registros > 10:
            resultados_texto = resultados.head(10).to_string(index=False)
            nota_adicional = f"\n\n(Se muestran solo los primeros 10 de {total_registros} registros encontrados)"
        else:
            resultados_texto = resultados.to_string(index=False)
            nota_adicional = ""
        
        prompt = f"""Eres un asistente virtual de USITTEL. Un usuario preguntÃ³:

PREGUNTA: {pregunta}

DATOS ENCONTRADOS en '{dataframe_nombre}' (Total: {total_registros} registros):
{resultados_texto}{nota_adicional}

TAREA:
Responde la pregunta del usuario de forma clara, profesional y amable, usando ÃšNICAMENTE la informaciÃ³n proporcionada.
- Si pregunta "cuÃ¡ntos", responde con el nÃºmero exacto: {total_registros}
- Si hay detalles especÃ­ficos, menciÃ³nalos
- No inventes ni agregues datos que no estÃ©n en la tabla
- Si hay muchos resultados, puedes resumir las estadÃ­sticas principales
"""
    
    return prompt

# ==================== PIPELINE COMPLETO RAG ====================

def procesar_pregunta(pregunta: str, dataframes: Dict[str, pd.DataFrame]) -> tuple[str, Optional[pd.DataFrame]]:
    """
    Pipeline completo de RAG (Retrieval Augmented Generation).
    
    Args:
        pregunta: Pregunta del usuario
        dataframes: Diccionario con todas las fuentes de datos
    
    Returns:
        Tupla (respuesta_texto, dataframe_encontrado)
    """
    # PASO 1: Router - Decidir dÃ³nde buscar
    with st.status("ğŸ¤” Analizando tu pregunta...", expanded=True) as status:
        st.write("1ï¸âƒ£ Determinando dÃ³nde buscar...")
        prompt_router = crear_prompt_router(pregunta, dataframes)
        respuesta_router = llamar_gemini(prompt_router, temperatura=0.1)
        
        parametros = extraer_json_de_respuesta(respuesta_router)
        
        if not parametros:
            status.update(label="âŒ No pude entender la pregunta", state="error")
            return "Lo siento, no pude interpretar tu pregunta. Â¿PodrÃ­as reformularla?", None
        
        if "error" in parametros:
            status.update(label="âŒ No encontrÃ© dÃ³nde buscar", state="error")
            return parametros["error"], None
        
        # Mostrar decisiÃ³n del router
        st.write(f"âœ… BuscarÃ© en: **{parametros['dataframe']}**")
        st.write(f"ğŸ“Š Columna: **{parametros['columna']}**")
        st.write(f"ğŸ” Valor: **{parametros['valor']}**")
        
        # PASO 2: Motor de BÃºsqueda - Ejecutar consulta
        st.write("2ï¸âƒ£ Buscando en los datos...")
        
        if parametros['dataframe'] not in dataframes:
            status.update(label="âŒ Fuente de datos no disponible", state="error")
            return f"La fuente de datos '{parametros['dataframe']}' no estÃ¡ disponible.", None
        
        df = dataframes[parametros['dataframe']]
        resultados = buscar_en_dataframe(df, parametros['columna'], parametros['valor'])
        
        st.write(f"ğŸ“¦ Encontrados: **{len(resultados)}** registros")
        
        # PASO 3: Sintetizador - Generar respuesta
        st.write("3ï¸âƒ£ Generando respuesta...")
        prompt_sintetizador = crear_prompt_sintetizador(pregunta, resultados, parametros['dataframe'])
        respuesta_final = llamar_gemini(prompt_sintetizador, temperatura=0.3)
        
        status.update(label="âœ… Â¡Listo!", state="complete")
    
    return respuesta_final, resultados

# ==================== INTERFAZ DE STREAMLIT ====================

def main():
    """FunciÃ³n principal de la aplicaciÃ³n."""
    
    # ConfiguraciÃ³n de la pÃ¡gina
    st.set_page_config(
        page_title="Chatbot USITTEL",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # TÃ­tulo
    st.title("ğŸ¤– Chatbot Interno USITTEL")
    st.markdown("*Asistente inteligente para consultas sobre clientes, NAPs, tickets y mÃ¡s*")
    
    # Sidebar con informaciÃ³n
    with st.sidebar:
        st.header("âš™ï¸ ConfiguraciÃ³n")
        
        # Verificar API Key
        if not GEMINI_API_KEY:
            st.error("âŒ API Key de Gemini no configurada")
            st.info("Configura la variable de entorno GEMINI_API_KEY o agrÃ©gala en .streamlit/secrets.toml")
            st.stop()
        else:
            st.success("âœ… API Key configurada")
        
        st.divider()
        st.header("ğŸ“Š Estado de Datos")
        
        # BotÃ³n para recargar datos
        if st.button("ğŸ”„ Recargar datos"):
            st.cache_data.clear()
            st.rerun()
    
    # Cargar datos
    dataframes = cargar_todos_los_datos()
    
    if not dataframes:
        st.error("âŒ No se pudieron cargar los datos. Verifica las URLs de Google Sheets.")
        st.stop()
    
    st.sidebar.info(f"ğŸ“¦ {len(dataframes)} fuentes de datos activas")
    
    # Inicializar historial de chat
    if "mensajes" not in st.session_state:
        st.session_state.mensajes = []
    
    # Mostrar historial de chat
    for mensaje in st.session_state.mensajes:
        with st.chat_message(mensaje["rol"]):
            st.markdown(mensaje["contenido"])
            if mensaje.get("dataframe") is not None and not mensaje["dataframe"].empty:
                with st.expander("ğŸ“Š Ver datos encontrados"):
                    st.dataframe(mensaje["dataframe"], use_container_width=True)
    
    # Input del usuario
    if pregunta := st.chat_input("Escribe tu pregunta aquÃ­..."):
        # Agregar pregunta al historial
        st.session_state.mensajes.append({"rol": "user", "contenido": pregunta})
        
        # Mostrar pregunta
        with st.chat_message("user"):
            st.markdown(pregunta)
        
        # Procesar y responder
        with st.chat_message("assistant"):
            respuesta, datos_encontrados = procesar_pregunta(pregunta, dataframes)
            st.markdown(respuesta)
            
            # Mostrar datos encontrados si existen
            if datos_encontrados is not None and not datos_encontrados.empty:
                with st.expander("ğŸ“Š Ver datos encontrados"):
                    st.dataframe(datos_encontrados, use_container_width=True)
        
        # Agregar respuesta al historial
        st.session_state.mensajes.append({
            "rol": "assistant",
            "contenido": respuesta,
            "dataframe": datos_encontrados
        })
    
    # Footer
    st.divider()
    st.caption(f"ğŸ• Ãšltima actualizaciÃ³n de datos: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.caption("ğŸ’¡ Tip: Los datos se actualizan automÃ¡ticamente cada 60 segundos")

if __name__ == "__main__":
    main()
